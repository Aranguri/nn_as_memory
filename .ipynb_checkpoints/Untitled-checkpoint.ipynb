{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a roadmap\n",
    "information extraction (IE) (Craven et al., 2000): also, what if a nn is connected to the internet?\n",
    "\n",
    "# Memory Networks\n",
    "Four components:\n",
    "* I: convert input to feature represntation\n",
    "* G: use input, m_i and all the memory to generate m_i\n",
    "* O: convert memory and input in feature repr. into feature repr. \n",
    "* R: convert feature representaiton to input. \n",
    "\n",
    "(O vs R: we want O to select the memories and R to process them and write the answer word by word.)\n",
    "\n",
    "## G comopnent\n",
    "Forgetting means removing the memory with the least expected utility.\n",
    "\n",
    "## O component\n",
    "We want to retrieve the useful memories for the input. \n",
    "\n",
    "$m^1 = argmax_{m_i} s_O(input, m_i)$\n",
    "\n",
    "$m^n = argmax_{m_i} s_O([input, m^1, ..., m^{n-1}], m_i)$\n",
    "\n",
    "It is as if the already-retrieved memories give us a better context to continue retrieving memories. \n",
    "\n",
    "## R component\n",
    "* m^k\n",
    "* argmax_{w \\in W} s_R([input, m^1, ..., m^k], w)\n",
    "* rnn(initial_h=?) \n",
    "\n",
    "## Score function s_O and s_R\n",
    "The function we have is s(x, y). x and y for $s_O$ are sentences. So before computing the similarity, we want to map them to a space better suited for computing the similarity. Thus, we define an transformation $\\tilde x = transform(x) = affine(bag\\_of\\_words(x)) = U bag\\_of\\_words(x).$ We then compute $similarity(transform(x), transform(x)) = transform(x)^Ttransform(x)$ \n",
    "\n",
    "{in the paper, they say the bag_of_words(x) function has three dimensions: one to use when the input is y and two to use when the input is x. why don't they use different functions for bag_of_words? I understand that for bag_of_words(x) you need at least D = 2|W| for you have words that come from the input x and from the memory, so we count the words appearance differently. But why don't we have $bag\\_of\\_words_x \\in R^{2|W|}$ and $bag\\_of\\_words_y \\in R^{|W|}$}\n",
    "\n",
    "## Training\n",
    "We have supervised information about the sentences that should have been selected and the response. We use the margin ranking loss that maximizes the distance between the score given to the correct memory location and that given to all the other memory locations. We only care about maximizing the distance up to a certain threshold. After that, the loss is the same regardless of the distance being the threshold or 3 * threshold.\n",
    "\n",
    "Randomized algorithms help: instead of going through all the other memory locations, we only compute the loss for a subset of the locations.\n",
    "\n",
    "In the following equations, $m_1$ and $m_2$ are the labels for the memory and $r$ is the label for the response. We want to minimize the following loss.\n",
    "\n",
    "$$\n",
    "L(U_O, U_R) = \\sum_{\\bar m \\neq m_1}max(0, \\gamma - [s_O(x, m_1) - s_O(x, \\bar m)]) + \\\\\n",
    "\\sum_{\\bar m \\neq m_2}max(0, \\gamma - [s_O([x, m_1], m_2) - s_O([x, m_1], \\bar m)]) + \\\\\n",
    "\\sum_{\\bar w \\neq r}max(0, \\gamma - [s_R([x, m_1, m_2], r) - s_R([x, m_1, m_2], \\bar w)])\\\\\n",
    "$$\n",
    "\n",
    "## Segment\n",
    "$linear\\_classifier(transform(x))$\n",
    "First, we transform x to an embedding space, easier to operate. Then, we use a linear classifier that based on the features of the embedding space, it outputs classifies whether we should segment the word stream into a sentence or not. {how do we input the words to this segmenter? do we add one word by one word to c?}\n",
    "\n",
    "## Efficiency\n",
    "### Hashing\n",
    "Requirements:\n",
    "* we have a function f that searches on average O(1)\n",
    "* we have a list of vectors A and a vector l\n",
    "* we want to search the vector in A that is more similar to l.\n",
    "* we don't want to compare l to every vector in A\n",
    "\n",
    "Process:\n",
    "* We compare l to A_i iff f(l) == f(A_i) \n",
    "\n",
    "An example of this is A being a list of real numbers, f being the floor function, and l being another real number. Thus, we don't compare l to every number in A. Instead, we compute the floor function of l, and compare the result to three buckets: the buckets where f(l) == f(A_i) and the buckets where f(l) +- 1 == f(A_i). In this way, we are completely sure that the result is correct. Notice that if we draw 100 numbers from an uniform distribution between 0 and 10, the complexity is the same as drawing 10n numbers from 0 to n (with n very large.) This happens because the complexity of indexing in an array is constant. \n",
    "\n",
    "### Implementation\n",
    "#### First option\n",
    "hash function: maps every word to a single bucket.\n",
    "Then, hash the input and every memory. (Notice that we need to compute the hash for the memory only once.) This hash function will return as many buckets as there are words in the sentence. \n",
    "Finally, we only compare the input to those memories that share at least one word with the sentence. \n",
    "\n",
    "#### Second option\n",
    "Instead of having one bucket for every word, we have k buckets where in each bucket we have similar words. We obtain this by running k-means. We then consider the memories that share buckets with the input. \n",
    "\n",
    "## Other concepts\n",
    "bag-of-words: a representation of a document where instead of storing the whole document, we store a dictionary with the key being the set of words and the value being the number of times they appear in the document.\n",
    "\n",
    "array index is O(1): We know that all the entries of an array are consecutively stored in memory. We also know the datatype of the array (and hence we know the memory size of every entry.) So, if we want to retrieve/store an entry in an array, we do it in O(1) by going to the memory address of first entry, and adding n * memory_size (with n being the position of the value in the array.) [1] \n",
    "\n",
    "{didn't understand note 3}\n",
    "\n",
    "is the softargmax also a gate?\n",
    "\n",
    "[1] I think that whenever there is something that we can do efficiently, we are taking advantage of some assumption. In this case, {what's happening?} \n",
    "\n",
    "\n",
    "https://homes.cs.washington.edu/~yejin/Papers/emnlp16_neuralchecklist.pdf\n",
    "https://arxiv.org/abs/1708.00781\n",
    "\n",
    "next steps\n",
    "* look for a dataset where it makes sense to have a huge memory\n",
    "* fix memory not changing in the same run\n",
    "\n",
    "differentiable datasets: word embeddings is an example. but much more information could go into this category. this type of representation is better for a nn. they could be improved by a community (commit system.) So internet isn't yet differentiable, but it could be cool to have a version of it that nn can easily read from. what's the difference between this and a standard dataset? In general, standard datasets are <input, output> pairs. But this differentiable datasets are <input, transform(input)>. For example, if we are using word embeddings, we have <word, vector> with the vector being the word embedding for the word. \n",
    "\n",
    "Why word embeddings work?\n",
    "I think they make a better representation for the nn. Two qualities: a) we train them with huge datasets, b) we use distributed representations\n",
    "\n",
    "The dataset used to train word embeddings such as glove is extremely massive. 1000B tokens. \n",
    "\n",
    "It would be interesting to take all the available data online and provide it for the nn in a way that makes it optimal. Why doesn't it just read the text? It's not optimal. Every neural net can learn to represent word embeddings, but it doesn't make sense to start from scratch every time. That's an advantage of electronical systems over humans: we can transfer some things of what we learned. \n",
    "\n",
    "Internet is massive. And it doesn't make sense for me that neural networks aren't taking advantage of it. A human connected to the internet is much more intelligent than if she were disconnected. \n",
    "\n",
    "I think it's similar to having a key-value memory: we are retrieving from memory by some query. \n",
    "\n",
    "Internet seems very smart on its own. In particular, I can complete the next sentence by using google. If neural nets are good with large datasets, then the internet is a good place for them. How the neural net learns isn't clear. One option could be to take the internet as a big matrix (as if it were a memory) and we allow the matrix to read from it (as memory networks.) We also can allow it to write, and that relates to having differentiable datasets. Consider that isn't necessary to go through all the internet for every iteration. Instead, we can have a hierarchical structure where we access everything in log(n) with n the size of the internet {is there something faster than log(n)? maybe hashing.} Internet takes around 10^18 bytes. So, if we use log(n) we have log_2(10^18) \\approx 60. What does that mean? It means that if we take 60 binary decisions, then we can decide what byte in the internet we are gonna read. \n",
    "\n",
    "In a way, the best way to learn is by asking questions, and what beter place than the internet to ask questions? (not to actually ask them, but to search for the answer to a similar, already-answered question.) \n",
    "\n",
    "The task\n",
    "\n",
    "what am I looking for? We want a task that requires to store a lot of facts and correctly retrieve a few of them at each time step. \n",
    "\n",
    "I need a way of measuring whether it's doing good or bad. But standard tasks like mnist or copy aren't useful because they contain only so much data. What we need is a task where the neural net receives a lot of different data. eg, it reads millions of wikipedia articles. remember that it doesn't need to remember every word of the article, they will be stored. what it needs is \"to go to a place that makes you remember\"* the memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Direction\n",
    "\n",
    "{is it a good policy to enforce coding every day? think about this}\n",
    "For humans, it made sense to have a long-term memory particular for every human. It seems impossible for this to be otherwise. One possibility could be a huge, central knowledge base. For primite humans, this could work only for non-quick decisions.\n",
    "Also, communicating information is so difficult! Talking seems to be one of the most efficient ways of communication information, and it seems slower than neurons communicating with each other. In a sense, we evolved to have this knowledge bases\n",
    "Libraries are an example of this. The internet is also an example of this.\n",
    "\n",
    "Let's see the case for a nn. Given that is possible, it seems better to access a knowledge base than to learn everything from scratch. Indeed, if we want to build long-term memories for neural networks, then it doesn't seem sensible to have a long-term memory for each individuals, as humans have. Instead, a differentiable knowledge base system seems to be the best thing. It has to be something like word-embeddings.\n",
    "Notice the powerfulness of word-embeddings. What we are doing is encoding relational information. It's just that. It's encoding how things interact. I say this because a given vector in a high-dimensional space doesn't have meaning. It's only when woman - man + king = queen when we can learn something useful. {is there a way of learning absolute meaning?} {what else other than +/- operations are there (ie other transformations)?}\n",
    "\n",
    "So, again. What's what we have with word embeddings? We have relative information.\n",
    "\n",
    "It's as if we have A => B as information, but we don't know whether A or B are true. We build a map with concepts that relate.\n",
    "\n",
    "Or also, it's as if we had y = 2x, or c = a + b. It's interesting that it could be the case that we don't need to feed the values a, b, or x.\n",
    "\n",
    "For instance, say we have \"Mary is twice as fast as Charles.\" Formally we have mary_speed = 2 * charles_speed\n",
    "If then we ask \"How fast is Mary?\" we can answer \"Twice as fast as charles.\"\n",
    "But I can ask you \"How fast is Mary (don't give an answer in terms of Charles).\" And say you know that charles runs at 8KM/H.\n",
    "Then you would say that Mary runs at 16KM/h.\n",
    "But it continues to be relative.\n",
    "What is one KM? One km is ten blocks. And what's a block? A hundred steps. And in this low-level, everything I have is related to images. I have something like an image to represent the distance of a block. I have the same to represent the distance of a step. It's interesting that we don't have one hardcoded explanation for a concept and everything builds from there (that is, we don't have an image for the distance of a step and everythign builds from there.) Instead, we have an image for the distance of a step, for a square, and even for a KM. And that complements with the abstract meaning of 100 step = 1 square.\n",
    "\n",
    "The low-level memories seem to be best represented as images. It seems as if humans have good primitives for dealing with images. What are these primitives about?\n",
    "\n",
    "primitives\n",
    "* storage: memorization techniques rely on converting symbols (eg sentences, cards) to images.\n",
    "* understanding: techniques for deep understanding rely on visualizations: plots, interactive ..., diagrams.\n",
    "\n",
    "\n",
    "Thus, storage and understanding are better if we use images as the resource. I think it's arbitrary. What's not arbitrary is that to get intelligence we need to get good manipulation of _some_ data type. we later can map other data types to it. We just need a translation between concepts in one type to other and we are done.\n",
    "\n",
    "Storage doesn't seem to be the limiting factor with intelligence. Or is it? It's interesting that AI research doesn't focus on storage. It's not clear that humans can store less information than a computer. What it does seem clear is that a human can't store as much information as the internet has.\n",
    "\n",
    "We shouldn't mix the information that could be consciously accessed with the information that a brain stores as a whole. Let's consider the conscious memories, which give us a lower-bound for the whole thing. I can easily retrieve memories of rides (caminos.) They are mostly images. I can retrieve some sequences of numbers. For a given person, I can retrieve their house, face, names, likings.\n",
    "\n",
    "It seems as if the problems we focus on neural nets are a little bit off from the problems we should focus for AGI. With actual nns we are training them from scratch to learn about one task. And we are saying that they aren't able to generalize. What if the generalization comes from the task that is trained in several tasks?\n",
    "\n",
    "How do we implement this? Take word embeddings for instance. There we are establishing relationships between concepts. But if we input \"derivatives.\" It could be better to focus on something smaller in the beginning. \n",
    "\n",
    "But I think it shouldn't be about synthethic tasks, because that's misleading. So I think the best thing is to take an interesting direction, and make it as simple as possible. \n",
    "\n",
    "But what are we doing?\n",
    "\n",
    "We want to add a long-term memory to a neural network (it could be individual or shared.) \n",
    "\n",
    "How do we add it? The addressing mechanism should be different to that of the short-term memories.\n",
    "* we can't read all the memories at once. So we need to try with something like the hopfield recursive net or a tree structure or hard attention\n",
    "* we need to know what we are going to store. So we need to think about a generalization of word embeddings\n",
    "* we need to know in what task we are going to apply this. We store a lot of wikipedia articles in the memory and we use wikidata to ask for properties. \n",
    "\n",
    "It's interesting that there is no backpropagation through large amounts of time.\n",
    "\n",
    "{idea for short-term memory: the less you attend something, the more it disappears from your short-term memory. Also, the more you attend something, the higher are the chances of saving it into your memory.}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
